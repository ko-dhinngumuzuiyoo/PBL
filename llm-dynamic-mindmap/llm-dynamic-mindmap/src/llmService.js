// src/llmService.js

/**
 * LLMã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹
 */
class BaseLLMService {
  constructor(config = {}) {
    this.config = config;
  }
  
  async generateRelatedWords(keyword, context = {}) {
    throw new Error('generateRelatedWords must be implemented');
  }
  
  async deepDive(nodeInfo, existingNeighbors, rootTheme) {
    throw new Error('deepDive must be implemented');
  }
  
  parseJsonResponse(text) {
    try {
      // JSONã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰JSONéƒ¨åˆ†ã‚’æŠ½å‡º
      const jsonMatch = text.match(/\[[\s\S]*\]/);
      if (jsonMatch) {
        return JSON.parse(jsonMatch[0]);
      }
      return JSON.parse(text);
    } catch (error) {
      console.error('JSON ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼:', error);
      console.error('å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ:', text);
      return [];
    }
  }
}

/**
 * Anthropic Claude APIã‚µãƒ¼ãƒ“ã‚¹
 */
export class AnthropicService extends BaseLLMService {
  constructor(config = {}) {
    super(config);
    this.apiKey = config.apiKey || '';
    this.model = config.model || 'claude-sonnet-4-20250514';
    this.maxTokens = config.maxTokens || 1024;
    this.temperature = config.temperature || 0.7;
  }
  
  async callAPI(prompt) {
    if (!this.apiKey) {
      throw new Error('Anthropic API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“');
    }
    
    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': this.apiKey,
        'anthropic-version': '2023-06-01'
      },
      body: JSON.stringify({
        model: this.model,
        max_tokens: this.maxTokens,
        messages: [{ role: 'user', content: prompt }]
      })
    });
    
    if (!response.ok) {
      const error = await response.json();
      throw new Error(`Anthropic API ã‚¨ãƒ©ãƒ¼: ${error.error?.message || response.statusText}`);
    }
    
    const data = await response.json();
    return data.content[0].text;
  }
  
  async generateRelatedWords(keyword, promptTemplate) {
    const prompt = promptTemplate.replace('{keyword}', keyword);
    const response = await this.callAPI(prompt);
    return this.parseJsonResponse(response);
  }
  
  async deepDive(nodeInfo, existingNeighbors, rootTheme, promptTemplate) {
    const prompt = promptTemplate
      .replace('{root_theme}', rootTheme)
      .replace('{current_node}', nodeInfo.label)
      .replace('{existing_neighbors}', existingNeighbors.join(', '));
    
    const response = await this.callAPI(prompt);
    return this.parseJsonResponse(response);
  }
}

/**
 * OpenAI APIã‚µãƒ¼ãƒ“ã‚¹
 */
export class OpenAIService extends BaseLLMService {
  constructor(config = {}) {
    super(config);
    this.apiKey = config.apiKey || '';
    this.model = config.model || 'gpt-4o-mini';
    this.maxTokens = config.maxTokens || 1024;
    this.temperature = config.temperature || 0.7;
  }
  
  async callAPI(prompt) {
    if (!this.apiKey) {
      throw new Error('OpenAI API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“');
    }
    
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`
      },
      body: JSON.stringify({
        model: this.model,
        max_tokens: this.maxTokens,
        temperature: this.temperature,
        messages: [{ role: 'user', content: prompt }]
      })
    });
    
    if (!response.ok) {
      const error = await response.json();
      throw new Error(`OpenAI API ã‚¨ãƒ©ãƒ¼: ${error.error?.message || response.statusText}`);
    }
    
    const data = await response.json();
    return data.choices[0].message.content;
  }
  
  async generateRelatedWords(keyword, promptTemplate) {
    const prompt = promptTemplate.replace('{keyword}', keyword);
    const response = await this.callAPI(prompt);
    return this.parseJsonResponse(response);
  }
  
  async deepDive(nodeInfo, existingNeighbors, rootTheme, promptTemplate) {
    const prompt = promptTemplate
      .replace('{root_theme}', rootTheme)
      .replace('{current_node}', nodeInfo.label)
      .replace('{existing_neighbors}', existingNeighbors.join(', '));
    
    const response = await this.callAPI(prompt);
    return this.parseJsonResponse(response);
  }
}

/**
 * ãƒ¢ãƒƒã‚¯LLMã‚µãƒ¼ãƒ“ã‚¹ï¼ˆAPIã‚­ãƒ¼ä¸è¦ã€ãƒ‡ãƒ¢ç”¨ï¼‰
 */
export class MockLLMService extends BaseLLMService {
  constructor(config = {}) {
    super(config);
    this.delay = config.delay || 500; // ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®é…å»¶
  }
  
  // ãƒˆãƒ”ãƒƒã‚¯åˆ¥ã®ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿
  mockData = {
    'default': [
      { word: 'åŸºç¤æ¦‚å¿µ', relation: 'åŸºæœ¬ã¨ãªã‚‹æ¦‚å¿µ' },
      { word: 'å¿œç”¨ä¾‹', relation: 'å®Ÿè·µçš„ãªå¿œç”¨' },
      { word: 'é–¢é€£æŠ€è¡“', relation: 'æŠ€è¡“çš„ãªé–¢é€£' },
      { word: 'æ­´å²çš„èƒŒæ™¯', relation: 'ç™ºå±•ã®çµŒç·¯' },
      { word: 'æœ€æ–°å‹•å‘', relation: 'ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰' }
    ],
    'æ©Ÿæ¢°å­¦ç¿’': [
      { word: 'ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯', relation: 'åŸºç›¤æŠ€è¡“' },
      { word: 'ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†', relation: 'å¿…è¦ãªã‚¹ãƒ†ãƒƒãƒ—' },
      { word: 'ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°', relation: 'é‡è¦ãªæŠ€è¡“' },
      { word: 'ãƒ¢ãƒ‡ãƒ«è©•ä¾¡', relation: 'å“è³ªç¢ºèª' },
      { word: 'ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿', relation: 'èª¿æ•´è¦ç´ ' },
      { word: 'éå­¦ç¿’', relation: 'æ³¨æ„ã™ã¹ãå•é¡Œ' }
    ],
    'æ·±å±¤å­¦ç¿’': [
      { word: 'å‹¾é…é™ä¸‹æ³•', relation: 'æœ€é©åŒ–æ‰‹æ³•' },
      { word: 'æ´»æ€§åŒ–é–¢æ•°', relation: 'æ§‹æˆè¦ç´ ' },
      { word: 'ãƒãƒƒãƒæ­£è¦åŒ–', relation: 'å®‰å®šåŒ–æŠ€è¡“' },
      { word: 'ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ', relation: 'æ­£å‰‡åŒ–æ‰‹æ³•' },
      { word: 'GPUè¨ˆç®—', relation: 'é«˜é€ŸåŒ–æŠ€è¡“' },
      { word: 'ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯', relation: 'é–‹ç™ºãƒ„ãƒ¼ãƒ«' }
    ],
    'Transformer': [
      { word: 'Self-Attention', relation: 'æ ¸å¿ƒãƒ¡ã‚«ãƒ‹ã‚ºãƒ ' },
      { word: 'Multi-Head Attention', relation: 'æ‹¡å¼µæ©Ÿèƒ½' },
      { word: 'Position Encoding', relation: 'ä½ç½®æƒ…å ±' },
      { word: 'Feed Forward', relation: 'æ§‹æˆå±¤' },
      { word: 'Layer Normalization', relation: 'æ­£è¦åŒ–' },
      { word: 'å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«', relation: 'ç™ºå±•å½¢' }
    ],
    'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹': [
      { word: 'çµ±è¨ˆåˆ†æ', relation: 'åŸºç¤ã‚¹ã‚­ãƒ«' },
      { word: 'ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–', relation: 'è¡¨ç¾æŠ€è¡“' },
      { word: 'SQL', relation: 'ãƒ‡ãƒ¼ã‚¿æ“ä½œ' },
      { word: 'Python', relation: 'ä¸»è¦è¨€èª' },
      { word: 'Pandas', relation: 'ãƒ‡ãƒ¼ã‚¿å‡¦ç†' },
      { word: 'ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿', relation: 'å¤§è¦æ¨¡å‡¦ç†' }
    ],
    'AI': [
      { word: 'æ©Ÿæ¢°å­¦ç¿’', relation: 'ä¸»è¦æŠ€è¡“' },
      { word: 'è‡ªç„¶è¨€èªå‡¦ç†', relation: 'å¿œç”¨åˆ†é‡' },
      { word: 'ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³', relation: 'å¿œç”¨åˆ†é‡' },
      { word: 'ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹', relation: 'å¿œç”¨åˆ†é‡' },
      { word: 'å€«ç†ãƒ»æ³•è¦åˆ¶', relation: 'ç¤¾ä¼šçš„èª²é¡Œ' },
      { word: 'AGI', relation: 'å°†æ¥ç›®æ¨™' }
    ],
    'Python': [
      { word: 'NumPy', relation: 'æ•°å€¤è¨ˆç®—' },
      { word: 'Pandas', relation: 'ãƒ‡ãƒ¼ã‚¿åˆ†æ' },
      { word: 'Matplotlib', relation: 'å¯è¦–åŒ–' },
      { word: 'Scikit-learn', relation: 'æ©Ÿæ¢°å­¦ç¿’' },
      { word: 'TensorFlow', relation: 'æ·±å±¤å­¦ç¿’' },
      { word: 'PyTorch', relation: 'æ·±å±¤å­¦ç¿’' }
    ]
  };
  
  async delay_ms(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
  
  findBestMatch(keyword) {
    const lowerKeyword = keyword.toLowerCase();
    for (const key of Object.keys(this.mockData)) {
      if (lowerKeyword.includes(key.toLowerCase()) || key.toLowerCase().includes(lowerKeyword)) {
        return this.mockData[key];
      }
    }
    return this.mockData['default'];
  }
  
  async generateRelatedWords(keyword, promptTemplate = '') {
    console.log(`ğŸ¤– [Mock LLM] ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ${keyword}ã€ã®é–¢é€£èªã‚’ç”Ÿæˆä¸­...`);
    
    await this.delay_ms(this.delay);
    
    const results = this.findBestMatch(keyword);
    
    // ãƒ©ãƒ³ãƒ€ãƒ ã«5-7å€‹é¸æŠ
    const count = 5 + Math.floor(Math.random() * 3);
    const shuffled = [...results].sort(() => Math.random() - 0.5);
    const selected = shuffled.slice(0, Math.min(count, shuffled.length));
    
    console.log(`âœ… [Mock LLM] ${selected.length}å€‹ã®é–¢é€£èªã‚’ç”Ÿæˆã—ã¾ã—ãŸ`);
    return selected;
  }
  
  async deepDive(nodeInfo, existingNeighbors, rootTheme, promptTemplate = '') {
    console.log(`ğŸ¤– [Mock LLM] ãƒãƒ¼ãƒ‰ã€Œ${nodeInfo.label}ã€ã‚’æ·±æ˜ã‚Šä¸­...`);
    
    await this.delay_ms(this.delay);
    
    // æ—¢å­˜ãƒãƒ¼ãƒ‰ã‚’é¿ã‘ãŸçµæœã‚’ç”Ÿæˆ
    const allResults = this.findBestMatch(nodeInfo.label);
    const filtered = allResults.filter(item => 
      !existingNeighbors.some(n => 
        n.toLowerCase().includes(item.word.toLowerCase()) ||
        item.word.toLowerCase().includes(n.toLowerCase())
      )
    );
    
    // çµæœãŒå°‘ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‹ã‚‰è¿½åŠ 
    let results = filtered;
    if (results.length < 3) {
      const defaults = this.mockData['default'].filter(item =>
        !existingNeighbors.some(n => 
          n.toLowerCase().includes(item.word.toLowerCase())
        )
      );
      results = [...results, ...defaults].slice(0, 5);
    }
    
    // ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
    const count = 4 + Math.floor(Math.random() * 3);
    const selected = [...results].sort(() => Math.random() - 0.5).slice(0, count);
    
    console.log(`âœ… [Mock LLM] ${selected.length}å€‹ã®æ·±æ˜ã‚Šçµæœã‚’ç”Ÿæˆã—ã¾ã—ãŸ`);
    return selected;
  }
}

/**
 * LLMã‚µãƒ¼ãƒ“ã‚¹ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼
 * @param {string} provider - ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å (anthropic, openai, mock)
 * @param {Object} config - è¨­å®š
 * @returns {BaseLLMService} LLMã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
 */
export function createLLMService(provider, config = {}) {
  switch (provider.toLowerCase()) {
    case 'anthropic':
      return new AnthropicService(config);
    case 'openai':
      return new OpenAIService(config);
    case 'mock':
    default:
      return new MockLLMService(config);
  }
}
